{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff70fb9e",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16cc4b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data  Experiment1  Experiment2\tExperiment3  Output\r\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "DATA PATHS\n",
    "'''\n",
    "#TOP_DIR = '/home/cgdubois/Notebooks/Iwashita'\n",
    "TOP_DIR = '/tf/Notebooks/Iwashita'\n",
    "\n",
    "IR_PATH = TOP_DIR + '/Data/IR/'\n",
    "RGB_PATH = TOP_DIR + '/Data/RGB/'\n",
    "MASKS_PATH = TOP_DIR + '/Data/Masks/'\n",
    "ANNOTATIONS_PATH = TOP_DIR + '/Data/Annotations/'\n",
    "\n",
    "'''\n",
    "OUTPUTS PATH\n",
    "'''\n",
    "WEIGHTS_PATH = TOP_DIR + '/output/Weights/'\n",
    "METRICS_PATH = TOP_DIR + '/output/Metrics/'\n",
    "\n",
    "!cd $TOP_DIR && ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71ad5699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-27 16:42:45.592806: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-27 16:42:46.852582: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-27 16:42:46.852820: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-27 16:42:46.856736: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-27 16:42:46.856983: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-27 16:42:46.857180: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-27 16:42:46.857373: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "SET GPU\n",
    "'''\n",
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "print(physical_devices)\n",
    "\n",
    "tf.config.set_visible_devices(physical_devices[1:],'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05159654",
   "metadata": {},
   "source": [
    "### Pre-Process Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02362a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images (loading, resizing, apply masks, etc)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 474/474 [00:09<00:00, 51.84it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "'''\n",
    "IMAGE PROPERTIES\n",
    "'''\n",
    "IMG_HEIGHT = 572\n",
    "IMG_WIDTH = 572\n",
    "\n",
    "RGB_CHANNELS = 3\n",
    "IR_CHANNELS = 1\n",
    "\n",
    "'''\n",
    "IMAGE LISTS\n",
    "'''\n",
    "img_list = [file for file in os.listdir(RGB_PATH) if file.lower().endswith('0000.png')]\n",
    "\n",
    "rgb_imgs = {}\n",
    "ir_imgs = {}\n",
    "\n",
    "'''\n",
    "MASKS\n",
    "'''\n",
    "rgb_mask = Image.open(os.path.join(MASKS_PATH, 'rgb_mask.ppm')).resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "ir_mask = Image.open(os.path.join(MASKS_PATH, 'ir_mask.png')).convert('L').resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "'''\n",
    "PRE-PROCESS\n",
    "'''\n",
    "print(\"Processing images (loading, resizing, apply masks, etc)...\")\n",
    "  \n",
    "for n, filename in tqdm(enumerate(img_list, start=0), total=len(img_list)):\n",
    "\n",
    "    # RGB Images - open, resize, apply mask\n",
    "    img = Image.open(os.path.join(RGB_PATH, filename)).resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "    rgb_imgs[filename] = np.asarray(img) * np.asarray(rgb_mask)\n",
    "\n",
    "    # IR Images - open, resize, apply mask\n",
    "    img = Image.open(os.path.join(IR_PATH, filename)).resize((IMG_WIDTH, IMG_HEIGHT)).convert('L')\n",
    "    ir_imgs[filename] = np.expand_dims(np.asarray(img) * np.asarray(ir_mask), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4339467c",
   "metadata": {},
   "source": [
    "### Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f814a1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading annotation files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 474/474 [00:06<00:00, 75.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoding annotation files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 474/474 [00:01<00:00, 398.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SAND: 6.32%\n",
      "SOIL: 60.07%\n",
      "BALLAST: 16.89%\n",
      "ROCK: 3.35%\n",
      "BEDROCK: 2.75%\n",
      "ROCKY_TERRAIN: 2.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "\n",
    "'''\n",
    "CLASSES\n",
    "'''\n",
    "classes = Enum('Classes', [\n",
    "    '__UNLABELED__',\n",
    "    'SAND',\n",
    "    'SOIL',\n",
    "    'BALLAST',\n",
    "    'ROCK',\n",
    "    'BEDROCK',\n",
    "    'ROCKY_TERRAIN'\n",
    "    ], start=0)\n",
    "\n",
    "num_classes = max(classes, key=lambda x: x.value).value + 1\n",
    "\n",
    "'''\n",
    "LOAD/DECODE ANNOTATION FILES\n",
    "'''\n",
    "annotations = {}\n",
    "\n",
    "print(\"Loading annotation files...\")\n",
    "\n",
    "for n, filename in tqdm(enumerate(img_list, start=0), total=len(img_list)):\n",
    "\n",
    "    img = Image.open(os.path.join(ANNOTATIONS_PATH, filename)).resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "    encoded = np.array(img)\n",
    "\n",
    "    label = np.bitwise_or(np.bitwise_or(\n",
    "        encoded[:, :, 0].astype(np.uint32),\n",
    "        encoded[:, :, 1].astype(np.uint32) << 8),\n",
    "        encoded[:, :, 2].astype(np.uint32) << 16)\n",
    "\n",
    "    annotations[filename] = label\n",
    "\n",
    "'''\n",
    "ONE-HOT ENCODE\n",
    "'''\n",
    "annotations_onehot = {}\n",
    "class_freq = {i: 0 for i in range(num_classes)}\n",
    "\n",
    "print(\"One-hot encoding annotation files...\")\n",
    "\n",
    "for n, filename in tqdm(enumerate(img_list, start=0), total=len(img_list)):\n",
    "\n",
    "    onehot_annotation = np.zeros((IMG_HEIGHT, IMG_WIDTH, num_classes), dtype=np.uint8)\n",
    "    \n",
    "    for c in range(num_classes):\n",
    "        mask = (annotations[filename] == c)\n",
    "        onehot_annotation[..., c] = mask\n",
    "        class_freq[c] += np.sum(mask)\n",
    "    \n",
    "    annotations_onehot[filename] = onehot_annotation\n",
    "\n",
    "total_pixels = sum(class_freq.values())\n",
    "\n",
    "class_percentages = {cls: (freq / total_pixels) * 100 for cls, freq in class_freq.items()}\n",
    "\n",
    "for cls, percentage in class_percentages.items():\n",
    "    if cls == 0:\n",
    "      print(\"\\n\")\n",
    "    if cls != 0:\n",
    "      print(f\"{classes(cls).name}: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc57596b",
   "metadata": {},
   "source": [
    "### Setting Up Experiment 1 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db6da40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def populate_data_sets(X_list, y_list, rgb_dict, ir_dict, annotations_dict):\n",
    "\n",
    "    X_rgb = np.zeros((len(X_list), IMG_HEIGHT, IMG_WIDTH, RGB_CHANNELS), dtype=np.uint8)\n",
    "    X_ir = np.zeros((len(X_list), IMG_HEIGHT, IMG_WIDTH, IR_CHANNELS), dtype=np.uint8)\n",
    "    y_data = np.zeros((len(y_list), IMG_HEIGHT, IMG_WIDTH, num_classes), dtype=np.uint8)\n",
    "\n",
    "    for i, fn in enumerate(X_list, start=0):\n",
    "        X_rgb[i] = rgb_dict[fn]\n",
    "        X_ir[i] = ir_dict[fn]\n",
    "        y_data[i] = annotations_dict[fn]\n",
    "    \n",
    "    return X_rgb, X_ir, y_data\n",
    "\n",
    "def calculate_class_frequency(annotation_array, num_classes):\n",
    "    pixel_count = np.zeros(num_classes)\n",
    "    \n",
    "    # Iterate over each class and count pixels\n",
    "    for i in range(num_classes):\n",
    "        pixel_count[i] = np.sum(annotation_array[:, :, :, i] == 1)\n",
    "        \n",
    "    # Compute class frequencies\n",
    "    class_frequency = pixel_count / np.sum(pixel_count)\n",
    "    \n",
    "    # Print out the frequency for each class\n",
    "    for cls in classes:\n",
    "        print(f\"{cls.name}: {class_frequency[cls.value]*100:.4f}\")\n",
    "        \n",
    "    return class_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa8cfd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating experiment 1 training data sets...\n",
      "Populating experiment 1 validation data sets...\n",
      "Populating experiment 1 test data sets...\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "FILTER EXPERIMENT 1 DATA\n",
    "'''\n",
    "exp1_pattern = r'^\\d{2}__2017-11-17-16(4[0-9]|[4-5]\\d)[0-9]{2}-0000.png$'\n",
    "exp1_img_list = [file for file in img_list if re.match(exp1_pattern, file)]\n",
    "\n",
    "'''\n",
    "SPLIT DATA\n",
    "'''\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    exp1_img_list, \n",
    "    exp1_img_list, \n",
    "    test_size=0.50, \n",
    "    train_size=0.50, \n",
    "    random_state=42, \n",
    "    shuffle=True)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, \n",
    "    y_temp, \n",
    "    test_size=0.50, \n",
    "    train_size=0.50, \n",
    "    random_state=42, \n",
    "    shuffle=False)\n",
    "\n",
    "print(\"Populating experiment 1 training data sets...\")\n",
    "exp1_rgb_X_train, exp1_ir_X_train, exp1_y_train = populate_data_sets(\n",
    "    X_train, y_train, rgb_imgs, ir_imgs, annotations_onehot)\n",
    "\n",
    "print(\"Populating experiment 1 validation data sets...\")  \n",
    "exp1_rgb_X_val, exp1_ir_X_val, exp1_y_val = populate_data_sets(\n",
    "    X_val, y_val, rgb_imgs, ir_imgs, annotations_onehot)\n",
    "\n",
    "print(\"Populating experiment 1 test data sets...\")  \n",
    "exp1_rgb_X_test, exp1_ir_X_test, exp1_y_test = populate_data_sets(\n",
    "    X_test, y_test, rgb_imgs, ir_imgs, annotations_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baf9d18",
   "metadata": {},
   "source": [
    "## Metrics Calculations Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8ad06af",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "INTERSECTION OVER UNION\n",
    "'''\n",
    "def iou(y_true, y_pred, num_classes):\n",
    "    intersection = np.histogram2d(y_true.flatten(), y_pred.flatten(), bins=num_classes)[0]\n",
    "    area_true = np.histogram(y_true, bins=num_classes)[0]\n",
    "    area_pred = np.histogram(y_pred, bins=num_classes)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    union[union == 0] = 1e-9\n",
    "    iou = intersection / union\n",
    "\n",
    "    return iou, np.mean(np.diag(iou))\n",
    "\n",
    "'''\n",
    "PIXEL ACCURACY\n",
    "'''\n",
    "def pixel_accuracy(y_true, y_pred):\n",
    "    return np.sum(y_true == y_pred) / y_true.size\n",
    "\n",
    "'''\n",
    "MEAN ACCURACY\n",
    "'''\n",
    "def mean_accuracy(y_true, y_pred, num_classes):\n",
    "    intersection = np.histogram2d(y_true.flatten(), y_pred.flatten(), bins=num_classes)[0]\n",
    "    area_true = np.histogram(y_true, bins=num_classes)[0]\n",
    "\n",
    "    area_true[area_true == 0] = 1e-9\n",
    "    accuracy = np.diag(intersection) / area_true\n",
    "\n",
    "    return np.mean(accuracy)\n",
    "\n",
    "'''\n",
    "FIRM-WEIGHT INTERSECTION OVER UNION\n",
    "'''\n",
    "def fw_iou(y_true, y_pred, num_classes):\n",
    "    intersection = np.histogram2d(y_true.flatten(), y_pred.flatten(), bins=num_classes)[0]\n",
    "    area_true = np.histogram(y_true, bins=num_classes)[0]\n",
    "    area_pred = np.histogram(y_pred, bins=num_classes)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    union[union == 0] = 1e-9\n",
    "    iou = intersection / union\n",
    "    fw_iou = np.sum(area_true * iou) / np.sum(area_true)\n",
    "\n",
    "    return fw_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "670b90e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, UpSampling2D\n",
    "from tensorflow.keras.layers import AveragePooling2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.image import resize, ResizeMethod\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import random\n",
    "\n",
    "\n",
    "INPUT_DIMS = (572, 572, 3)\n",
    "\n",
    "'''\n",
    "Atrous Spatial Pyramid Pooling\n",
    "'''\n",
    "def ASPP(inputs):\n",
    "  '''\n",
    "  INPUT SHAPE\n",
    "  '''\n",
    "  shape = inputs.shape\n",
    "\n",
    "  '''\n",
    "  POOLING\n",
    "  '''\n",
    "  y_pool = AveragePooling2D(pool_size=(shape[1], shape[2]), name='average_pooling')(inputs)\n",
    "  y_pool = Conv2D(filters=256, kernel_size=1, padding='same', use_bias=False)(y_pool)\n",
    "  y_pool = BatchNormalization(name=f'bn_1')(y_pool)\n",
    "  y_pool = Activation('relu', name=f'relu_1')(y_pool)\n",
    "  y_pool = UpSampling2D((shape[1], shape[2]), interpolation=\"bilinear\")(y_pool)\n",
    "\n",
    "  '''\n",
    "  RATE 1 BLOCK\n",
    "  '''\n",
    "  y_1 = Conv2D(filters=256, kernel_size=1, dilation_rate=1, padding='same', use_bias=False)(inputs)\n",
    "  y_1 = BatchNormalization()(y_1)\n",
    "  y_1 = Activation('relu')(y_1)\n",
    "\n",
    "  '''\n",
    "  RATE 6 BLOCK\n",
    "  '''\n",
    "  y_6 = Conv2D(filters=256, kernel_size=3, dilation_rate=6, padding='same', use_bias=False)(inputs)\n",
    "  y_6 = BatchNormalization()(y_6)\n",
    "  y_6 = Activation('relu')(y_6)\n",
    "\n",
    "  '''\n",
    "  RATE 12 BLOCK\n",
    "  '''\n",
    "  y_12 = Conv2D(filters=256, kernel_size=3, dilation_rate=12, padding='same', use_bias=False)(inputs)\n",
    "  y_12 = BatchNormalization()(y_12)\n",
    "  y_12 = Activation('relu')(y_12)\n",
    "\n",
    "  y_18 = Conv2D(filters=256, kernel_size=3, dilation_rate=18, padding='same', use_bias=False)(inputs)\n",
    "  y_18 = BatchNormalization()(y_18)\n",
    "  y_18 = Activation('relu')(y_18)\n",
    "\n",
    "  y = Concatenate()([y_pool, y_1, y_6, y_12, y_18])\n",
    "\n",
    "  y = Conv2D(filters=256, kernel_size=1, dilation_rate=1, padding='same', use_bias=False)(y)\n",
    "  y = BatchNormalization()(y)\n",
    "  y = Activation('relu')(y)\n",
    "\n",
    "  '''\n",
    "  RETURN\n",
    "  '''\n",
    "  return y\n",
    "\n",
    "def DeepLab(shape):\n",
    "  '''\n",
    "  INPUTS\n",
    "  '''\n",
    "  inputs = Input(shape)\n",
    "\n",
    "  '''\n",
    "  RESNET101\n",
    "  '''\n",
    "  base_model = ResNet101(weights='imagenet', include_top=False, input_tensor=inputs)\n",
    "  image_features = base_model.get_layer('conv4_block6_out').output\n",
    "  x_a = ASPP(image_features)\n",
    "  x_a = UpSampling2D((4, 4), interpolation=\"bilinear\")(x_a)\n",
    "\n",
    "  '''\n",
    "  LOW LEVEL FEATURES\n",
    "  '''\n",
    "  x_b = base_model.get_layer('conv2_block2_out').output\n",
    "  x_b = Conv2D(filters=48, kernel_size=1, padding='same', use_bias=False)(x_b)\n",
    "  x_b = BatchNormalization()(x_b)\n",
    "  x_b = Activation('relu')(x_b)\n",
    "  x_b = resize(x_b, (144, 144), method=ResizeMethod.BILINEAR)\n",
    "\n",
    "  x = Concatenate()([x_a, x_b])\n",
    "\n",
    "  '''\n",
    "  CONV BLOCK 1\n",
    "  '''\n",
    "  x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu',use_bias=False)(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "\n",
    "  '''\n",
    "  CONV BLOCK 2\n",
    "  '''\n",
    "  x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu', use_bias=False)(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = UpSampling2D((4, 4), interpolation=\"bilinear\")(x)\n",
    "\n",
    "  '''\n",
    "  OUTPUT\n",
    "  '''\n",
    "  x = resize(x, (572, 572), method=ResizeMethod.BILINEAR)\n",
    "  x = Conv2D(7, (1, 1), activation='softmax')(x)\n",
    "\n",
    "  '''\n",
    "  MODEL\n",
    "  '''\n",
    "  model = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "  '''\n",
    "  RETURN\n",
    "  '''\n",
    "  return model\n",
    "\n",
    "'''\n",
    "TRAIN\n",
    "'''\n",
    "def DeepLab_Train(model, X_train, y_train, X_val, y_val, weights_filename):\n",
    "    \n",
    "    try:\n",
    "        with tf.device('/device:GPU:0'):\n",
    "            model.compile(\n",
    "                optimizer=Adam(learning_rate=1e-4), \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "            \n",
    "            callbacks = [\n",
    "                ModelCheckpoint(\n",
    "                    weights_filename, \n",
    "                    save_best_only=True, \n",
    "                    save_weights_only=True, \n",
    "                    verbose=1),\n",
    "                EarlyStopping(patience=10, verbose=1),\n",
    "                ReduceLROnPlateau(factor=0.1, patience=5, min_lr=1e-7, verbose=1)\n",
    "            ]\n",
    "            \n",
    "            batch_size = 4\n",
    "            epochs = 500\n",
    "            \n",
    "            history = model.fit(\n",
    "                [X_train], y_train,\n",
    "                validation_data=([X_val], y_val),\n",
    "                batch_size=batch_size, epochs=epochs, callbacks=callbacks, verbose=2\n",
    "            )\n",
    "            \n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "'''\n",
    "LOAD\n",
    "'''\n",
    "def DeepLab_Load(weights_filename):\n",
    "  \n",
    "  model = DeepLab(INPUT_DIMS)\n",
    "  model.load_weights(weights_filename)\n",
    "  model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "  return model\n",
    "\n",
    "'''\n",
    "SCORE\n",
    "'''\n",
    "def DeepLab_Score(model, weights_filename, metrics_filename, X_test, y_test):\n",
    "\n",
    "  # Evaluate the model on the test data in batches\n",
    "  batch_size = 20\n",
    "  num_samples = X_test.shape[0]\n",
    "  scores = []\n",
    "  for i in range(0, num_samples, batch_size):\n",
    "    X_batch = X_test[i:i+batch_size]\n",
    "    y_batch = y_test[i:i+batch_size]\n",
    "    score = model.evaluate(X_batch, y_batch, verbose=0)\n",
    "    scores.append(score)\n",
    "\n",
    "  # Compute the average test loss and accuracy\n",
    "  test_loss = sum(score[0] for score in scores) / len(scores)\n",
    "  test_acc = sum(score[1] for score in scores) / len(scores)\n",
    "\n",
    "  # Print and save the test metrics\n",
    "  print(\"Test loss:\", test_loss)\n",
    "  print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "  #with open(metrics_filename, \"a\") as f:\n",
    "  #    f.write(f\"\\Test Loss: {test_loss}\\n\")\n",
    "  #    f.write(f\"\\Test Accuracy: {test_acc}\\n\")\n",
    "\n",
    "'''\n",
    "DISPLAY RANDOM RESULT\n",
    "'''\n",
    "def DeepLab_Display(X_test, y_test, y_pred, num_classes=7):\n",
    "\n",
    "  n = random.randint(0, len(X_test))\n",
    "\n",
    "  print(\"RGB/IR Image\")\n",
    "  imshow(X_test[n])\n",
    "  axis('off')\n",
    "  show()\n",
    "\n",
    "  print(\"Ground Truth Annotation\")\n",
    "  display_one_hot_annotation(y_test[n], num_classes)\n",
    "\n",
    "  print(\"Predicted\")\n",
    "  display_one_hot_annotation(y_pred[n], num_classes)\n",
    "\n",
    "'''\n",
    "METRICS\n",
    "'''\n",
    "def DeepLab_Metrics(y_test, y_pred, metrics_filename):\n",
    "\n",
    "  y_pred_classes = np.argmax(y_pred, axis=-1)\n",
    "  y_true_classes = np.argmax(y_test, axis=-1)\n",
    "\n",
    "  iou_values, mean_iou = iou(y_true_classes, y_pred_classes, num_classes)\n",
    "  pixel_acc = pixel_accuracy(y_true_classes, y_pred_classes)\n",
    "  mean_acc = mean_accuracy(y_true_classes, y_pred_classes, num_classes)\n",
    "  fw_iou_value = fw_iou(y_true_classes, y_pred_classes, num_classes)\n",
    "\n",
    "  print(f\"Mean IoU: {mean_iou}\")\n",
    "  print(f\"Pixel accuracy: {pixel_acc}\")\n",
    "  print(f\"Mean accuracy: {mean_acc}\")\n",
    "  print(f\"Frequency-Weighted IoU: {fw_iou_value}\")\n",
    "  \n",
    "  with open(metrics_filename, \"a\") as f:\n",
    "    f.write(\"\\nIoU Values:\\n\")\n",
    "    for i, iou_val in enumerate(iou_values):\n",
    "        f.write(f\"Class {i}: {iou_val}\\n\")\n",
    "    f.write(f\"\\nMean IoU: {mean_iou}\\n\")\n",
    "    f.write(f\"Pixel Accuracy: {pixel_acc}\\n\")\n",
    "    f.write(f\"Mean Accuracy: {mean_acc}\\n\")\n",
    "    f.write(f\"Frequency Weighted IoU: {fw_iou_value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a8c05a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "FILENAMES\n",
    "'''\n",
    "exp1_weights_filename = os.path.join(WEIGHTS_PATH, 'deeplab_baseline_experiment1.h5')\n",
    "exp1_metrics_filename = os.path.join(METRICS_PATH, 'deeplab_baseline_experiment1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8b33c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-27 16:52:58.794272: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-05-27 16:53:02.434754: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0xa7b9b950 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-27 16:53:02.434785: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla P40, Compute Capability 6.1\n",
      "2023-05-27 16:53:02.487264: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-27 16:53:02.796513: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 3.05884, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 43s - loss: 1.5107 - accuracy: 0.4753 - val_loss: 3.0588 - val_accuracy: 0.0941 - lr: 1.0000e-04 - 43s/epoch - 6s/step\n",
      "Epoch 2/500\n",
      "\n",
      "Epoch 2: val_loss did not improve from 3.05884\n",
      "7/7 - 3s - loss: 0.7937 - accuracy: 0.7745 - val_loss: 3.2603 - val_accuracy: 0.0929 - lr: 1.0000e-04 - 3s/epoch - 446ms/step\n",
      "Epoch 3/500\n",
      "\n",
      "Epoch 3: val_loss did not improve from 3.05884\n",
      "7/7 - 3s - loss: 0.5916 - accuracy: 0.8394 - val_loss: 3.1926 - val_accuracy: 0.0980 - lr: 1.0000e-04 - 3s/epoch - 449ms/step\n",
      "Epoch 4/500\n",
      "\n",
      "Epoch 4: val_loss improved from 3.05884 to 3.00039, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 4s - loss: 0.5312 - accuracy: 0.8540 - val_loss: 3.0004 - val_accuracy: 0.1130 - lr: 1.0000e-04 - 4s/epoch - 515ms/step\n",
      "Epoch 5/500\n",
      "\n",
      "Epoch 5: val_loss improved from 3.00039 to 2.62441, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 4s - loss: 0.3652 - accuracy: 0.8892 - val_loss: 2.6244 - val_accuracy: 0.1304 - lr: 1.0000e-04 - 4s/epoch - 516ms/step\n",
      "Epoch 6/500\n",
      "\n",
      "Epoch 6: val_loss improved from 2.62441 to 2.51062, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 4s - loss: 0.2797 - accuracy: 0.9352 - val_loss: 2.5106 - val_accuracy: 0.1458 - lr: 1.0000e-04 - 4s/epoch - 516ms/step\n",
      "Epoch 7/500\n",
      "\n",
      "Epoch 7: val_loss did not improve from 2.51062\n",
      "7/7 - 3s - loss: 0.2506 - accuracy: 0.9369 - val_loss: 2.5157 - val_accuracy: 0.1286 - lr: 1.0000e-04 - 3s/epoch - 451ms/step\n",
      "Epoch 8/500\n",
      "\n",
      "Epoch 8: val_loss improved from 2.51062 to 2.31099, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 4s - loss: 0.2205 - accuracy: 0.9538 - val_loss: 2.3110 - val_accuracy: 0.1570 - lr: 1.0000e-04 - 4s/epoch - 515ms/step\n",
      "Epoch 9/500\n",
      "\n",
      "Epoch 9: val_loss improved from 2.31099 to 1.80860, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 4s - loss: 0.1824 - accuracy: 0.9532 - val_loss: 1.8086 - val_accuracy: 0.3099 - lr: 1.0000e-04 - 4s/epoch - 516ms/step\n",
      "Epoch 10/500\n",
      "\n",
      "Epoch 10: val_loss improved from 1.80860 to 1.51955, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 4s - loss: 0.1691 - accuracy: 0.9604 - val_loss: 1.5196 - val_accuracy: 0.4510 - lr: 1.0000e-04 - 4s/epoch - 516ms/step\n",
      "Epoch 11/500\n",
      "\n",
      "Epoch 11: val_loss improved from 1.51955 to 1.41254, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 4s - loss: 0.1461 - accuracy: 0.9673 - val_loss: 1.4125 - val_accuracy: 0.5165 - lr: 1.0000e-04 - 4s/epoch - 518ms/step\n",
      "Epoch 12/500\n",
      "\n",
      "Epoch 12: val_loss improved from 1.41254 to 1.26187, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 4s - loss: 0.1917 - accuracy: 0.9534 - val_loss: 1.2619 - val_accuracy: 0.6402 - lr: 1.0000e-04 - 4s/epoch - 529ms/step\n",
      "Epoch 13/500\n",
      "\n",
      "Epoch 13: val_loss improved from 1.26187 to 1.14154, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 4s - loss: 0.2271 - accuracy: 0.9394 - val_loss: 1.1415 - val_accuracy: 0.6932 - lr: 1.0000e-04 - 4s/epoch - 514ms/step\n",
      "Epoch 14/500\n",
      "\n",
      "Epoch 14: val_loss improved from 1.14154 to 1.05077, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 4s - loss: 0.1449 - accuracy: 0.9619 - val_loss: 1.0508 - val_accuracy: 0.7174 - lr: 1.0000e-04 - 4s/epoch - 529ms/step\n",
      "Epoch 15/500\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.05077\n",
      "7/7 - 3s - loss: 0.1835 - accuracy: 0.9534 - val_loss: 1.1003 - val_accuracy: 0.7238 - lr: 1.0000e-04 - 3s/epoch - 453ms/step\n",
      "Epoch 16/500\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.05077\n",
      "7/7 - 3s - loss: 0.1614 - accuracy: 0.9612 - val_loss: 1.1794 - val_accuracy: 0.7053 - lr: 1.0000e-04 - 3s/epoch - 451ms/step\n",
      "Epoch 17/500\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.05077\n",
      "7/7 - 3s - loss: 0.1373 - accuracy: 0.9643 - val_loss: 1.1676 - val_accuracy: 0.7095 - lr: 1.0000e-04 - 3s/epoch - 450ms/step\n",
      "Epoch 18/500\n",
      "\n",
      "Epoch 18: val_loss improved from 1.05077 to 0.99005, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 4s - loss: 0.1426 - accuracy: 0.9673 - val_loss: 0.9901 - val_accuracy: 0.7579 - lr: 1.0000e-04 - 4s/epoch - 511ms/step\n",
      "Epoch 19/500\n",
      "\n",
      "Epoch 19: val_loss improved from 0.99005 to 0.92959, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 4s - loss: 0.1323 - accuracy: 0.9659 - val_loss: 0.9296 - val_accuracy: 0.7681 - lr: 1.0000e-04 - 4s/epoch - 516ms/step\n",
      "Epoch 20/500\n",
      "\n",
      "Epoch 20: val_loss improved from 0.92959 to 0.88981, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 4s - loss: 0.1056 - accuracy: 0.9783 - val_loss: 0.8898 - val_accuracy: 0.7847 - lr: 1.0000e-04 - 4s/epoch - 518ms/step\n",
      "Epoch 21/500\n",
      "\n",
      "Epoch 21: val_loss improved from 0.88981 to 0.84691, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 4s - loss: 0.1037 - accuracy: 0.9770 - val_loss: 0.8469 - val_accuracy: 0.7960 - lr: 1.0000e-04 - 4s/epoch - 526ms/step\n",
      "Epoch 22/500\n",
      "\n",
      "Epoch 22: val_loss improved from 0.84691 to 0.80993, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 4s - loss: 0.1019 - accuracy: 0.9782 - val_loss: 0.8099 - val_accuracy: 0.7946 - lr: 1.0000e-04 - 4s/epoch - 534ms/step\n",
      "Epoch 23/500\n",
      "\n",
      "Epoch 23: val_loss improved from 0.80993 to 0.74525, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 4s - loss: 0.1010 - accuracy: 0.9756 - val_loss: 0.7453 - val_accuracy: 0.8040 - lr: 1.0000e-04 - 4s/epoch - 538ms/step\n",
      "Epoch 24/500\n",
      "\n",
      "Epoch 24: val_loss improved from 0.74525 to 0.67924, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 4s - loss: 0.0813 - accuracy: 0.9814 - val_loss: 0.6792 - val_accuracy: 0.8104 - lr: 1.0000e-04 - 4s/epoch - 575ms/step\n",
      "Epoch 25/500\n",
      "\n",
      "Epoch 25: val_loss improved from 0.67924 to 0.64817, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 4s - loss: 0.0721 - accuracy: 0.9828 - val_loss: 0.6482 - val_accuracy: 0.8091 - lr: 1.0000e-04 - 4s/epoch - 595ms/step\n",
      "Epoch 26/500\n",
      "\n",
      "Epoch 26: val_loss improved from 0.64817 to 0.62624, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 4s - loss: 0.0718 - accuracy: 0.9830 - val_loss: 0.6262 - val_accuracy: 0.8089 - lr: 1.0000e-04 - 4s/epoch - 632ms/step\n",
      "Epoch 27/500\n",
      "\n",
      "Epoch 27: val_loss improved from 0.62624 to 0.60346, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 5s - loss: 0.0813 - accuracy: 0.9804 - val_loss: 0.6035 - val_accuracy: 0.8067 - lr: 1.0000e-04 - 5s/epoch - 689ms/step\n",
      "Epoch 28/500\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.60346\n",
      "7/7 - 5s - loss: 0.0724 - accuracy: 0.9836 - val_loss: 0.6150 - val_accuracy: 0.7980 - lr: 1.0000e-04 - 5s/epoch - 704ms/step\n",
      "Epoch 29/500\n",
      "\n",
      "Epoch 29: val_loss improved from 0.60346 to 0.59889, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 6s - loss: 0.0674 - accuracy: 0.9830 - val_loss: 0.5989 - val_accuracy: 0.8028 - lr: 1.0000e-04 - 6s/epoch - 801ms/step\n",
      "Epoch 30/500\n",
      "\n",
      "Epoch 30: val_loss improved from 0.59889 to 0.57880, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 6s - loss: 0.0766 - accuracy: 0.9818 - val_loss: 0.5788 - val_accuracy: 0.8101 - lr: 1.0000e-04 - 6s/epoch - 864ms/step\n",
      "Epoch 31/500\n",
      "\n",
      "Epoch 31: val_loss improved from 0.57880 to 0.56416, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 6s - loss: 0.0720 - accuracy: 0.9835 - val_loss: 0.5642 - val_accuracy: 0.8146 - lr: 1.0000e-04 - 6s/epoch - 870ms/step\n",
      "Epoch 32/500\n",
      "\n",
      "Epoch 32: val_loss improved from 0.56416 to 0.54539, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 6s - loss: 0.0599 - accuracy: 0.9847 - val_loss: 0.5454 - val_accuracy: 0.8186 - lr: 1.0000e-04 - 6s/epoch - 878ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/500\n",
      "\n",
      "Epoch 33: val_loss improved from 0.54539 to 0.53367, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 6s - loss: 0.0620 - accuracy: 0.9853 - val_loss: 0.5337 - val_accuracy: 0.8192 - lr: 1.0000e-04 - 6s/epoch - 886ms/step\n",
      "Epoch 34/500\n",
      "\n",
      "Epoch 34: val_loss improved from 0.53367 to 0.51942, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 6s - loss: 0.0571 - accuracy: 0.9855 - val_loss: 0.5194 - val_accuracy: 0.8212 - lr: 1.0000e-04 - 6s/epoch - 889ms/step\n",
      "Epoch 35/500\n",
      "\n",
      "Epoch 35: val_loss improved from 0.51942 to 0.51007, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 6s - loss: 0.0586 - accuracy: 0.9855 - val_loss: 0.5101 - val_accuracy: 0.8201 - lr: 1.0000e-04 - 6s/epoch - 919ms/step\n",
      "Epoch 36/500\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.51007\n",
      "7/7 - 6s - loss: 0.0593 - accuracy: 0.9856 - val_loss: 0.5160 - val_accuracy: 0.8154 - lr: 1.0000e-04 - 6s/epoch - 910ms/step\n",
      "Epoch 37/500\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.51007\n",
      "7/7 - 8s - loss: 0.0623 - accuracy: 0.9851 - val_loss: 0.5228 - val_accuracy: 0.8124 - lr: 1.0000e-04 - 8s/epoch - 1s/step\n",
      "Epoch 38/500\n",
      "\n",
      "Epoch 38: val_loss improved from 0.51007 to 0.50818, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 9s - loss: 0.0517 - accuracy: 0.9863 - val_loss: 0.5082 - val_accuracy: 0.8139 - lr: 1.0000e-04 - 9s/epoch - 1s/step\n",
      "Epoch 39/500\n",
      "\n",
      "Epoch 39: val_loss improved from 0.50818 to 0.49882, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 10s - loss: 0.0506 - accuracy: 0.9868 - val_loss: 0.4988 - val_accuracy: 0.8125 - lr: 1.0000e-04 - 10s/epoch - 1s/step\n",
      "Epoch 40/500\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.49882\n",
      "7/7 - 9s - loss: 0.0539 - accuracy: 0.9863 - val_loss: 0.5011 - val_accuracy: 0.8116 - lr: 1.0000e-04 - 9s/epoch - 1s/step\n",
      "Epoch 41/500\n",
      "\n",
      "Epoch 41: val_loss improved from 0.49882 to 0.49298, saving model to /tf/Notebooks/Iwashita/Output/Weights/deeplab_baseline_experiment1.h5\n",
      "7/7 - 10s - loss: 0.0502 - accuracy: 0.9866 - val_loss: 0.4930 - val_accuracy: 0.8144 - lr: 1.0000e-04 - 10s/epoch - 1s/step\n",
      "Epoch 42/500\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.49298\n",
      "7/7 - 9s - loss: 0.0519 - accuracy: 0.9867 - val_loss: 0.5032 - val_accuracy: 0.8111 - lr: 1.0000e-04 - 9s/epoch - 1s/step\n",
      "Epoch 43/500\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.49298\n",
      "7/7 - 9s - loss: 0.0492 - accuracy: 0.9875 - val_loss: 0.5057 - val_accuracy: 0.8086 - lr: 1.0000e-04 - 9s/epoch - 1s/step\n",
      "Epoch 44/500\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.49298\n",
      "7/7 - 9s - loss: 0.0506 - accuracy: 0.9871 - val_loss: 0.5018 - val_accuracy: 0.8111 - lr: 1.0000e-04 - 9s/epoch - 1s/step\n",
      "Epoch 45/500\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.49298\n",
      "7/7 - 10s - loss: 0.0531 - accuracy: 0.9862 - val_loss: 0.5115 - val_accuracy: 0.8163 - lr: 1.0000e-04 - 10s/epoch - 1s/step\n",
      "Epoch 46/500\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.49298\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "7/7 - 13s - loss: 0.0481 - accuracy: 0.9879 - val_loss: 0.5346 - val_accuracy: 0.8100 - lr: 1.0000e-04 - 13s/epoch - 2s/step\n",
      "Epoch 47/500\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.49298\n",
      "7/7 - 15s - loss: 0.0473 - accuracy: 0.9874 - val_loss: 0.5328 - val_accuracy: 0.8098 - lr: 1.0000e-05 - 15s/epoch - 2s/step\n",
      "Epoch 48/500\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.49298\n",
      "7/7 - 16s - loss: 0.0486 - accuracy: 0.9876 - val_loss: 0.5292 - val_accuracy: 0.8102 - lr: 1.0000e-05 - 16s/epoch - 2s/step\n",
      "Epoch 49/500\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.49298\n",
      "7/7 - 20s - loss: 0.0505 - accuracy: 0.9876 - val_loss: 0.5261 - val_accuracy: 0.8097 - lr: 1.0000e-05 - 20s/epoch - 3s/step\n",
      "Epoch 50/500\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.49298\n",
      "7/7 - 20s - loss: 0.0512 - accuracy: 0.9875 - val_loss: 0.5225 - val_accuracy: 0.8098 - lr: 1.0000e-05 - 20s/epoch - 3s/step\n",
      "Epoch 51/500\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.49298\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "7/7 - 19s - loss: 0.0652 - accuracy: 0.9824 - val_loss: 0.5194 - val_accuracy: 0.8097 - lr: 1.0000e-05 - 19s/epoch - 3s/step\n",
      "Epoch 51: early stopping\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAIN\n",
    "'''\n",
    "exp1_model = DeepLab(INPUT_DIMS)\n",
    "\n",
    "DeepLab_Train(\n",
    "    exp1_model, exp1_rgb_X_train, exp1_y_train, exp1_rgb_X_val, exp1_y_val, exp1_weights_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ac43479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6896021962165833\n",
      "Test accuracy: 0.7545408606529236\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tf/Notebooks/Iwashita/Output/Metrics/deeplab_baseline_experiment1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mSCORE\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mDeepLab_Score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp1_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp1_weights_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp1_metrics_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp1_rgb_X_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp1_y_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 191\u001b[0m, in \u001b[0;36mDeepLab_Score\u001b[0;34m(model, weights_filename, metrics_filename, X_test, y_test)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_loss)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_acc)\n\u001b[0;32m--> 191\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmetrics_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    192\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    193\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tf/Notebooks/Iwashita/Output/Metrics/deeplab_baseline_experiment1.txt'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "SCORE\n",
    "'''\n",
    "DeepLab_Score(\n",
    "    exp1_model, exp1_weights_filename, exp1_metrics_filename, exp1_rgb_X_test, exp1_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4230ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
