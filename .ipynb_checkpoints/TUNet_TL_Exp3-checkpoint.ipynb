{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff70fb9e",
   "metadata": {},
   "source": [
    "# TUNet TL Exp 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52240bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "IMPORTS\n",
    "'''\n",
    "import tensorflow as tf\n",
    "from tensorflow.image import resize, ResizeMethod\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "from numpy import load\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import get_ipython\n",
    "from IPython.terminal.interactiveshell import TerminalInteractiveShell\n",
    "\n",
    "shell = TerminalInteractiveShell.instance()\n",
    "\n",
    "'''\n",
    "DATA PATHS\n",
    "'''\n",
    "TOP_DIR = '/tf/Notebooks/Iwashita'\n",
    "\n",
    "TRAIN_DIR = TOP_DIR + '/Data/Preprocessed_wAugmentation/Experiment3/Train'\n",
    "VAL_DIR = TOP_DIR + '/Data/Preprocessed_wAugmentation/Experiment3/Validate'\n",
    "TEST_DIR = TOP_DIR + '/Data/Preprocessed_wAugmentation/Experiment3/Test'\n",
    "\n",
    "'''\n",
    "OUTPUTS PATH\n",
    "'''\n",
    "WEIGHTS_PATH = TOP_DIR + '/Output/Weights/'\n",
    "METRICS_PATH = TOP_DIR + '/Output/Metrics/'\n",
    "\n",
    "'''\n",
    "GPU\n",
    "'''\n",
    "gpu_p40 = '/device:GPU:1'\n",
    "gpu_1660 = '/device:GPU:0'\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "'''\n",
    "TRAINING DATA\n",
    "'''\n",
    "print(TRAIN_DIR)\n",
    "!cd /tf/Notebooks/Iwashita/Data/Preprocessed_wAugmentation/Experiment2/Train && ls\n",
    "\n",
    "exp3_rgb_X_train = load(TRAIN_DIR + '/exp3_rgb_X_train.npy')\n",
    "exp3_ir_X_train = load(TRAIN_DIR + '/exp3_ir_X_train.npy')\n",
    "exp3_y_train = load(TRAIN_DIR + '/exp3_y_train.npy')\n",
    "\n",
    "'''\n",
    "VALIDATION DATA\n",
    "'''\n",
    "exp3_rgb_X_val = load(VAL_DIR + '/exp3_rgb_X_val.npy')\n",
    "exp3_ir_X_val = load(VAL_DIR + '/exp3_ir_X_val.npy')\n",
    "exp3_y_val =load(VAL_DIR + '/exp3_y_val.npy')\n",
    "\n",
    "'''\n",
    "TEST DATA\n",
    "'''\n",
    "exp3_rgb_X_test_a = load(TEST_DIR + '/exp3_rgb_X_test_a.npy')\n",
    "exp3_ir_X_test_a = load(TEST_DIR + '/exp3_ir_X_test_a.npy')\n",
    "exp3_y_test_a =load(TEST_DIR + '/exp3_y_test_a.npy')\n",
    "\n",
    "exp3_rgb_X_test_b = load(TEST_DIR + '/exp3_rgb_X_test_b.npy')\n",
    "exp3_ir_X_test_b = load(TEST_DIR + '/exp3_ir_X_test_b.npy')\n",
    "exp3_y_test_b =load(TEST_DIR + '/exp3_y_test_b.npy')\n",
    "\n",
    "'''\n",
    "INTERSECTION OVER UNION\n",
    "'''\n",
    "def iou(y_true, y_pred, num_classes):\n",
    "    intersection = np.histogram2d(y_true.flatten(), y_pred.flatten(), bins=num_classes)[0]\n",
    "    area_true = np.histogram(y_true, bins=num_classes)[0]\n",
    "    area_pred = np.histogram(y_pred, bins=num_classes)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    union[union == 0] = 1e-9\n",
    "    iou = intersection / union\n",
    "\n",
    "    return iou, np.mean(np.diag(iou))\n",
    "\n",
    "'''\n",
    "PIXEL ACCURACY\n",
    "'''\n",
    "def pixel_accuracy(y_true, y_pred):\n",
    "    return np.sum(y_true == y_pred) / y_true.size\n",
    "\n",
    "'''\n",
    "MEAN ACCURACY\n",
    "'''\n",
    "def mean_accuracy(y_true, y_pred, num_classes):\n",
    "    intersection = np.histogram2d(y_true.flatten(), y_pred.flatten(), bins=num_classes)[0]\n",
    "    area_true = np.histogram(y_true, bins=num_classes)[0]\n",
    "\n",
    "    area_true[area_true == 0] = 1e-9\n",
    "    accuracy = np.diag(intersection) / area_true\n",
    "\n",
    "    return np.mean(accuracy)\n",
    "\n",
    "'''\n",
    "FREQUENCY-WEIGHTED INTERSECTION OVER UNION\n",
    "'''\n",
    "def fw_iou(y_true, y_pred, num_classes):\n",
    "    intersection = np.histogram2d(y_true.flatten(), y_pred.flatten(), bins=num_classes)[0]\n",
    "    area_true = np.histogram(y_true, bins=num_classes)[0]\n",
    "    area_pred = np.histogram(y_pred, bins=num_classes)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    union[union == 0] = 1e-9\n",
    "    iou = intersection / union\n",
    "    fw_iou = np.sum(area_true * iou) / np.sum(area_true)\n",
    "\n",
    "    return fw_iou\n",
    "\n",
    "def display_one_hot_annotation(annotations_onehot):\n",
    "    label = np.argmax(annotations_onehot, axis=-1)\n",
    "    cmap = plt.get_cmap('tab10', 7)\n",
    "\n",
    "    plt.imshow(label, cmap=cmap)\n",
    "    plt.colorbar(ticks=range(num_classes), format=plt.FuncFormatter(lambda val, loc: {\n",
    "        0: \"unlabeled\",\n",
    "        1: \"sand\",\n",
    "        2: \"soil\",\n",
    "        3: \"ballast\",\n",
    "        4: \"rock\",\n",
    "        5: \"bedrock\",\n",
    "        6: \"rocky terrain\"\n",
    "    }[val]))\n",
    "    plt.show()\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b70e554",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MODEL PARAMS\n",
    "'''\n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 1000 \n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "PATIENCE = 15\n",
    "FACTOR = 0.1\n",
    "\n",
    "EXP3_FILENAME = \"augmented_tunet_tl_exp3_batch{}_epoch{}_lr{}_p{}_f{}\".format(\n",
    "    BATCH_SIZE, EPOCHS, LEARNING_RATE, PATIENCE, FACTOR)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d98e7ac",
   "metadata": {},
   "source": [
    "### TUNet TL Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b5db62",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MODEL\n",
    "'''\n",
    "def ContractionPath(inputs, _padding='same', _activation='relu'):\n",
    "    c1 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\n",
    "    c1 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(0.25)(p1)\n",
    "\n",
    "    c2 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(p1)\n",
    "    c2 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(0.5)(p2)\n",
    "\n",
    "    c3 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(p2)\n",
    "    c3 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(0.5)(p3)\n",
    "\n",
    "    c4 = Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(p3)\n",
    "    c4 = Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(0.5)(p4)\n",
    "    \n",
    "    '''\n",
    "    RETURN\n",
    "    '''\n",
    "    return c1, c2, c3, c4, p4\n",
    "\n",
    "def ExpansionPath(c1, c2, c3, c4, p4, _padding='same', _activation='relu'):    \n",
    "    cm = Conv2D(1024, (3, 3), activation=\"relu\", padding=\"same\")(p4)\n",
    "    cm = Conv2D(1024, (3, 3), activation=\"relu\", padding=\"same\")(cm)\n",
    "    \n",
    "    deconv4 = Conv2DTranspose(512, (3, 3), strides=(2, 2), padding=\"same\")(cm)\n",
    "    c4 = resize(c4, (deconv4.shape[1], deconv4.shape[2]), method=ResizeMethod.BILINEAR)\n",
    "    uconv4 = concatenate([deconv4, c4])\n",
    "    uconv4 = Dropout(0.5)(uconv4)\n",
    "    uconv4 = Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n",
    "    uconv4 = Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n",
    "\n",
    "    deconv3 = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    c3 = resize(c3, (deconv3.shape[1], deconv3.shape[2]), method=ResizeMethod.BILINEAR)\n",
    "    uconv3 = concatenate([deconv3, c3])\n",
    "    uconv3 = Dropout(0.5)(uconv3)\n",
    "    uconv3 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n",
    "    uconv3 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n",
    "\n",
    "    deconv2 = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    c2 = resize(c2, (deconv2.shape[1], deconv2.shape[2]), method=ResizeMethod.BILINEAR)\n",
    "    uconv2 = concatenate([deconv2, c2])\n",
    "    uconv2 = Dropout(0.5)(uconv2)\n",
    "    uconv2 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
    "    uconv2 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
    "\n",
    "    deconv1 = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    c1 = resize(c1, (deconv1.shape[1], deconv1.shape[2]), method=ResizeMethod.BILINEAR)\n",
    "    uconv1 = concatenate([deconv1, c1])\n",
    "    uconv1 = Dropout(0.5)(uconv1)\n",
    "    uconv1 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
    "    uconv1 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
    "    \n",
    "    return uconv1\n",
    "\n",
    "def TUNet_TL():\n",
    "    '''\n",
    "    INPUT\n",
    "    '''\n",
    "    # Expected inputs are an RGB and an IR image\n",
    "    input_rgb = Input((572, 572, 3))\n",
    "    input_ir = Input((572, 572))\n",
    "    input_ir = tf.expand_dims(input_ir, axis=-1)\n",
    "    \n",
    "    '''\n",
    "    CONTRACTION PATH\n",
    "    '''\n",
    "    c1_rgb, c2_rgb, c3_rgb, c4_rgb, p4_rgb = ContractionPath(input_rgb)\n",
    "    c1_ir, c2_ir, c3_ir, c4_ir, p4_ir = ContractionPath(input_ir)\n",
    "    \n",
    "    '''\n",
    "    EXPANSION PATH\n",
    "    '''\n",
    "    cout_rgb = ExpansionPath(c1_rgb, c2_rgb, c3_rgb, c4_rgb, p4_rgb)\n",
    "    cout_ir = ExpansionPath(c1_ir, c2_ir, c3_ir, c4_ir, p4_ir)\n",
    "    \n",
    "    cout_cat = concatenate([cout_rgb, cout_ir], axis=-1)\n",
    "\n",
    "    '''\n",
    "    OUTPUT\n",
    "    '''\n",
    "    softmax_output = Conv2D(7, (1, 1), padding=\"same\", activation='softmax')(cout_cat)\n",
    "    softmax_output = resize(softmax_output, (572, 572), method=ResizeMethod.BILINEAR)\n",
    "\n",
    "    '''\n",
    "    RETURN\n",
    "    '''\n",
    "    return Model(inputs=[input_rgb, input_ir], outputs=softmax_output)\n",
    "\n",
    "'''\n",
    "TRAIN\n",
    "'''\n",
    "def TUNet_Train(model, weights_filename, \n",
    "               X_rgb_train, X_ir_train, y_train, \n",
    "               X_rgb_val, X_ir_val, y_val):\n",
    "\n",
    "    try:\n",
    "        with tf.device(gpu_p40):\n",
    "            \n",
    "            model.compile(\n",
    "                optimizer=Adam(learning_rate=LEARNING_RATE), \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "            callbacks = [\n",
    "                ModelCheckpoint(weights_filename, save_best_only=True, save_weights_only=True, verbose=1),\n",
    "                EarlyStopping(patience=PATIENCE, verbose=1),\n",
    "                ReduceLROnPlateau(factor=FACTOR, patience=PATIENCE, min_lr=LEARNING_RATE, verbose=1)]\n",
    "                \n",
    "            history = model.fit(\n",
    "                [X_rgb_train, X_ir_train], y_train,\n",
    "                validation_data=([X_rgb_val, X_ir_val], y_val),\n",
    "                batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=callbacks, verbose=2)\n",
    "        \n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        \n",
    "'''\n",
    "SCORE\n",
    "'''\n",
    "def TUNet_Score(model, weights_filename, metrics_filename, \n",
    "                X_rgb_test, X_ir_test, y_test):\n",
    "    \n",
    "    try:\n",
    "        with tf.device(gpu_p40):\n",
    "            model.load_weights(weights_filename)\n",
    "\n",
    "            score = model.evaluate([X_rgb_test, X_ir_test], y_test, batch_size=2, verbose=1)\n",
    "\n",
    "            print(\"Test loss:\", score[0])\n",
    "            print(\"Test accuracy:\", score[1])\n",
    "\n",
    "            with open(metrics_filename, \"a\") as f:\n",
    "                f.write(f\"\\Test Loss: {score[0]}\\n\")\n",
    "                f.write(f\"\\Test Accuracy: {score[1]}\\n\")\n",
    "                \n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "'''\n",
    "PREDICT\n",
    "'''\n",
    "def TUNet_Predict(model, X_rgb_test, X_ir_test):\n",
    "    try:\n",
    "        with tf.device(gpu_p40):\n",
    "            pred = model.predict([X_rgb_test, X_ir_test], batch_size=2)\n",
    "            \n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        \n",
    "    return pred\n",
    "\n",
    "'''\n",
    "DISPLAY RANDOM RESULT\n",
    "'''\n",
    "def TUNet_Display(X_rgb_test, X_ir_test, y_test, y_pred):\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(10, 6))\n",
    "    n = random.randint(0, len(X_rgb_test)-1)\n",
    "    cmap = plt.get_cmap('tab10', 7)\n",
    "    \n",
    "    axes[0].imshow(X_rgb_test[n])\n",
    "    axes[1].imshow(X_ir_test[n], cmap='gray')\n",
    "    axes[2].imshow(np.argmax(y_test[n], axis=-1), cmap=cmap)\n",
    "    axes[3].imshow(np.argmax(y_pred[n], axis=-1), cmap=cmap)\n",
    "                                           \n",
    "    axes[0].set_title(\"RGB\")\n",
    "    axes[1].set_title(\"IR\")\n",
    "    axes[2].set_title(\"Annotation\")\n",
    "    axes[3].set_title(\"Predicted\")\n",
    "    \n",
    "    for ax in axes.flatten():\n",
    "        ax.axis(\"off\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "        \n",
    "'''\n",
    "CALCULATE METRICS\n",
    "'''\n",
    "def TUNet_Metrics(y_test, y_pred, metrics_filename):\n",
    "    y_pred_classes = np.argmax(y_pred, axis=-1)\n",
    "    y_true_classes = np.argmax(y_test, axis=-1)\n",
    "    \n",
    "    num_classes = 7\n",
    "    \n",
    "    iou_values, mean_iou = iou(y_true_classes, y_pred_classes, num_classes)\n",
    "    pixel_acc = pixel_accuracy(y_true_classes, y_pred_classes)\n",
    "    mean_acc = mean_accuracy(y_true_classes, y_pred_classes, num_classes)\n",
    "    fw_iou_value = fw_iou(y_true_classes, y_pred_classes, num_classes)\n",
    "    \n",
    "    print(f\"Mean IoU: {mean_iou}\")\n",
    "    print(f\"Pixel accuracy: {pixel_acc}\")\n",
    "    print(f\"Mean accuracy: {mean_acc}\")\n",
    "    print(f\"Frequency-Weighted IoU: {fw_iou_value}\")\n",
    "    \n",
    "    with open(metrics_filename, \"a\") as f:\n",
    "        f.write(\"\\nIoU Values:\\n\")\n",
    "        \n",
    "        for i, iou_val in enumerate(iou_values):\n",
    "            f.write(f\"Class {i}: {iou_val}\\n\")\n",
    "        f.write(f\"\\nMean IoU: {mean_iou}\\n\")\n",
    "        f.write(f\"Pixel Accuracy: {pixel_acc}\\n\")\n",
    "        f.write(f\"Mean Accuracy: {mean_acc}\\n\")\n",
    "        f.write(f\"Frequency Weighted IoU: {fw_iou_value}\\n\")\n",
    "    \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba66ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with tf.device(gpu_p40):\n",
    "        exp3_model = TUNet_TL()\n",
    "except RuntimeError as e:\n",
    "    print(e)\n",
    "    \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66a0305",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUNet_Train(exp3_model, os.path.join(WEIGHTS_PATH, EXP3_FILENAME + '.h5'), \n",
    "                exp3_rgb_X_train, exp3_ir_X_train, exp3_y_train,\n",
    "                exp3_rgb_X_val, exp3_ir_X_val, exp3_y_val)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb310984",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ff05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = TUNet_Score(\n",
    "    exp3_model, \n",
    "    os.path.join(WEIGHTS_PATH, EXP3_FILENAME + '.h5'),\n",
    "    os.path.join(METRICS_PATH, EXP3_FILENAME + '.txt'),\n",
    "    exp3_rgb_X_test_a,\n",
    "    exp3_ir_X_test_a,\n",
    "    exp3_y_test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3074a39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_a = TUNet_Predict(exp3_model, exp3_rgb_X_test_a, exp3_ir_X_test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45dcaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUNet_Display(exp3_rgb_X_test_a, exp3_ir_X_test_a, exp3_y_test_a, y_pred_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43579c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUNet_Metrics(exp3_y_test_a, y_pred_a, os.path.join(METRICS_PATH, EXP3_FILENAME + '.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c2206",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabe61ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = TUNet_Score(\n",
    "    exp3_model, \n",
    "    os.path.join(WEIGHTS_PATH, EXP3_FILENAME + '.h5'),\n",
    "    os.path.join(METRICS_PATH, EXP3_FILENAME + '.txt'),\n",
    "    exp3_rgb_X_test_b,\n",
    "    exp3_ir_X_test_b,\n",
    "    exp3_y_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3b5521",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_b = TUNet_Predict(exp3_model, exp3_rgb_X_test_b, exp3_ir_X_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2611df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUNet_Display(exp3_rgb_X_test_b, exp3_ir_X_test_b, exp3_y_test_b, y_pred_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4aa047",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUNet_Metrics(exp3_y_test_b, y_pred_b, os.path.join(METRICS_PATH, EXP3_FILENAME + '.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b26b17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
