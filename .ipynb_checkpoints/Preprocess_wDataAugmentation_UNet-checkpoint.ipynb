{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def490ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DATA PATHS\n",
    "'''\n",
    "TOP_DIR = '/tf/Notebooks/Iwashita'\n",
    "\n",
    "IR_PATH = TOP_DIR + '/Data/IR/'\n",
    "RGB_PATH = TOP_DIR + '/Data/RGB/'\n",
    "MASKS_PATH = TOP_DIR + '/Data/Masks/'\n",
    "ANNOTATIONS_PATH = TOP_DIR + '/Data/Annotations/'\n",
    "\n",
    "'''\n",
    "OUTPUTS PATH\n",
    "'''\n",
    "WEIGHTS_PATH = TOP_DIR + '/output/Weights/'\n",
    "METRICS_PATH = TOP_DIR + '/output/Metrics/'\n",
    "\n",
    "!cd $TOP_DIR && ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97a4bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import numpy as np\n",
    "from numpy import asarray, save\n",
    "import os\n",
    "from PIL import Image\n",
    "import re\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.pyplot import axis, figure, imshow, show, subplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1c7e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "SUPPORTING FUNCTIONS\n",
    "'''\n",
    "\n",
    "'''\n",
    "CLASSES\n",
    "'''\n",
    "classes = Enum('Classes', [\n",
    "    'UNLABELED',\n",
    "    'SAND',\n",
    "    'SOIL',\n",
    "    'BALLAST',\n",
    "    'ROCK',\n",
    "    'BEDROCK',\n",
    "    'ROCKY_TERRAIN'\n",
    "    ], start=0)\n",
    "\n",
    "num_classes = max(classes, key=lambda x: x.value).value + 1\n",
    "\n",
    "'''\n",
    "POPULATE DATA SETS\n",
    "'''\n",
    "def populate_data_sets(X_list, y_list, rgb_dict, ir_dict, annotations_dict):\n",
    "    X_rgb = []\n",
    "    X_ir = []\n",
    "    y_data =[]\n",
    "\n",
    "    for i, fn in enumerate(X_list, start=0):        \n",
    "        X_rgb.append(rgb_dict[fn])\n",
    "        X_ir.append(ir_dict[fn])\n",
    "        y_data.append(annotations_dict[fn])\n",
    "\n",
    "    return np.array(X_rgb), np.array(X_ir), np.array(y_data)\n",
    "\n",
    "'''\n",
    "CALCULATE CLASS FREQUENCY\n",
    "'''\n",
    "def calculate_class_frequency_single(annotation_array):\n",
    "    num_classes = annotation_array.shape[2]\n",
    "    \n",
    "    pixel_count = np.zeros(num_classes)\n",
    "\n",
    "    # Iterate over each class and count pixels\n",
    "    for i in range(num_classes):\n",
    "        pixel_count[i] = np.sum(annotation_array[:, :, i] == 1)\n",
    "\n",
    "    # Compute class frequencies\n",
    "    class_frequency = pixel_count / np.sum(pixel_count)\n",
    "\n",
    "    # Print out the frequency for each class\n",
    "    for cls in classes:\n",
    "        print(f\"{cls.name}: {class_frequency[cls.value]*100:.4f}\")\n",
    "        \n",
    "    return class_frequency\n",
    "\n",
    "def calculate_class_frequency_set(annotation_array):\n",
    "    num_classes = annotation_array.shape[3]\n",
    "    \n",
    "    pixel_count = np.zeros(num_classes)\n",
    "    \n",
    "    # Iterate over each class and count pixels\n",
    "    for i in range(num_classes):\n",
    "        pixel_count[i] = np.sum(annotation_array[:, :, :, i] == 1)\n",
    "        \n",
    "    # Compute class frequencies\n",
    "    class_frequency = pixel_count / np.sum(pixel_count)\n",
    "    \n",
    "    # Print out the frequency for each class\n",
    "    for cls in classes:\n",
    "        print(f\"{cls.name}: {class_frequency[cls.value]*100:.4f}\")\n",
    "        \n",
    "    return class_frequency\n",
    "\n",
    "'''\n",
    "FIND MAX CLASS\n",
    "'''\n",
    "def find_max_class(annotation_array):\n",
    "    num_classes = annotation_array.shape[2]\n",
    "    \n",
    "    pixel_count = np.zeros(num_classes)\n",
    "\n",
    "    # Iterate over each class and count pixels\n",
    "    for i in range(num_classes):\n",
    "        pixel_count[i] = np.sum(annotation_array[:, :, i] == 1)\n",
    "\n",
    "    # Compute class frequencies\n",
    "    class_frequency = pixel_count / np.sum(pixel_count)\n",
    "    \n",
    "    # Find max class\n",
    "    max_freq_index = np.argmax(class_frequency)\n",
    "        \n",
    "    return classes(max_freq_index), class_frequency[classes(max_freq_index).value]\n",
    "\n",
    "'''\n",
    "ONE-HOT ANNOTATION CHECK\n",
    "'''\n",
    "def display_onehot_annotation(annotations_onehot):\n",
    "    label = np.argmax(annotations_onehot, axis=-1)\n",
    "    cmap = plt.get_cmap('tab10', 7)\n",
    "\n",
    "    plt.imshow(label, cmap=cmap)\n",
    "    plt.colorbar(ticks=range(num_classes), format=plt.FuncFormatter(lambda val, loc: {\n",
    "        0: \"unlabeled\",\n",
    "        1: \"sand\",\n",
    "        2: \"soil\",\n",
    "        3: \"ballast\",\n",
    "        4: \"rock\",\n",
    "        5: \"bedrock\",\n",
    "        6: \"rocky terrain\"\n",
    "    }[val]))\n",
    "    plt.show()\n",
    "\n",
    "'''\n",
    "AUGMENTED FILENAME\n",
    "'''\n",
    "def generate_augmented_filename(filename, tag):\n",
    "    fn, ext = os.path.splitext(filename)\n",
    "    \n",
    "    return fn + tag + ext\n",
    "\n",
    "'''\n",
    "AUGMENT IMAGES\n",
    "'''\n",
    "def augment_image(filename, img):\n",
    "    img_dict = {}\n",
    "    img_shape = img.shape\n",
    "\n",
    "    if (len(img_shape) == 3):\n",
    "        img_array = np.zeros((5, img_shape[0], img_shape[1], img_shape[2]), dtype=np.uint8)\n",
    "    else:\n",
    "        img_array = np.zeros((5, img_shape[0], img_shape[1]), dtype=np.uint8)\n",
    "    \n",
    "    # Rotate 90 degrees\n",
    "    fn = generate_augmented_filename(filename, \"_rot90\")\n",
    "    aug = np.rot90(img)\n",
    "    img_dict[fn] = aug\n",
    "    \n",
    "    # Rotate 180 degrees\n",
    "    fn = generate_augmented_filename(filename, \"_rot180\")\n",
    "    aug = np.rot90(img, k=2)\n",
    "    img_dict[fn] = aug\n",
    "    \n",
    "    # Rotate 270 degrees\n",
    "    fn = generate_augmented_filename(filename, \"_rot270\")\n",
    "    aug = np.rot90(img, k=3)\n",
    "    img_dict[fn] = aug\n",
    "    \n",
    "    # Flip horizontally\n",
    "    fn = generate_augmented_filename(filename, \"_flipH\")\n",
    "    aug = np.fliplr(img)\n",
    "    img_dict[fn] = aug\n",
    "    \n",
    "    # Flip vertically\n",
    "    fn = generate_augmented_filename(filename, \"_flipV\")\n",
    "    aug = np.flipud(img)\n",
    "    img_dict[fn] = aug\n",
    "    \n",
    "    return img_dict\n",
    "\n",
    "def print_augmented_images(original_img, augmented_imgs):\n",
    "    imgs = list(augmented_imgs.values())\n",
    "    shape = imgs[0].shape\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n",
    "    \n",
    "    # IR Images\n",
    "    if (len(shape) == 2):\n",
    "        axes[0,0].imshow(original_img, cmap='gray')\n",
    "        axes[0,1].imshow(imgs[0], cmap='gray')\n",
    "        axes[0,2].imshow(imgs[1], cmap='gray')\n",
    "        axes[1,0].imshow(imgs[2], cmap='gray')\n",
    "        axes[1,1].imshow(imgs[3], cmap='gray')\n",
    "        axes[1,2].imshow(imgs[4], cmap='gray')\n",
    "    \n",
    "    # RBG Images\n",
    "    elif(len(shape) == 3 and shape[2] == 3):\n",
    "        axes[0,0].imshow(original_img)\n",
    "        axes[0,1].imshow(imgs[0])\n",
    "        axes[0,2].imshow(imgs[1])\n",
    "        axes[1,0].imshow(imgs[2])\n",
    "        axes[1,1].imshow(imgs[3])\n",
    "        axes[1,2].imshow(imgs[4])\n",
    "        \n",
    "    # Annotation Images\n",
    "    elif(len(shape) == 3 and shape[2] == 7):\n",
    "        \n",
    "        cmap = plt.get_cmap('tab10', 7)\n",
    "    \n",
    "        axes[0,0].imshow(np.argmax(original_img, axis=-1), cmap=cmap)\n",
    "        \n",
    "        # Showing colorbar for original image only\n",
    "        fig.colorbar(axes[0,0].imshow(np.argmax(original_img, axis=-1), cmap=cmap), ax=axes[0,0], ticks=range(7), format=plt.FuncFormatter(lambda val, loc: {\n",
    "            0: \"unlabeled\",\n",
    "            1: \"sand\",\n",
    "            2: \"soil\",\n",
    "            3: \"ballast\",\n",
    "            4: \"rock\",\n",
    "            5: \"bedrock\",\n",
    "            6: \"rocky terrain\"\n",
    "        }[val]))\n",
    "        \n",
    "        axes[0,1].imshow(np.argmax(imgs[0], axis=-1), cmap=cmap)\n",
    "        axes[0,2].imshow(np.argmax(imgs[1], axis=-1), cmap=cmap)\n",
    "        axes[1,0].imshow(np.argmax(imgs[2], axis=-1), cmap=cmap)\n",
    "        axes[1,1].imshow(np.argmax(imgs[3], axis=-1), cmap=cmap)\n",
    "        axes[1,2].imshow(np.argmax(imgs[4], axis=-1), cmap=cmap)\n",
    "    \n",
    "    else:\n",
    "        print(\"Unexpected image dimensions: \" + repr(len(shape)))\n",
    "        \n",
    "    axes[0,0].set_title(\"Original\")\n",
    "    axes[0,1].set_title(\"Rotated 90\")\n",
    "    axes[0,2].set_title(\"Rotated 180\")\n",
    "    axes[1,0].set_title(\"Rotated 270\")\n",
    "    axes[1,1].set_title(\"Flipped Horizontal\")\n",
    "    axes[1,2].set_title(\"Flipped Vertical\")\n",
    "    \n",
    "    for ax in axes.flatten():\n",
    "        ax.axis(\"off\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0f1a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "IMAGE PROPERTIES - Original image dimensions are 800x600\n",
    "'''\n",
    "IMG_HEIGHT = 572\n",
    "IMG_WIDTH = 572\n",
    "\n",
    "RGB_CHANNELS = 3\n",
    "IR_CHANNELS = 1\n",
    "\n",
    "'''\n",
    "IMAGE LISTS\n",
    "'''\n",
    "img_list = [file for file in os.listdir(RGB_PATH) if file.lower().endswith('0000.png')]\n",
    "\n",
    "rgb_imgs = {}\n",
    "ir_imgs = {}\n",
    "\n",
    "'''\n",
    "LOAD MASKS\n",
    "'''\n",
    "rgb_mask = np.array(Image.open(os.path.join(MASKS_PATH, 'rgb_mask.ppm'))) / 255.0\n",
    "ir_mask = np.array(Image.open(os.path.join(MASKS_PATH, 'ir_mask.png')))[:,:,0] / 255.0\n",
    "\n",
    "'''\n",
    "LOAD AND NORMALIZE\n",
    "'''\n",
    "print(\"Processing RGB images...\")\n",
    "\n",
    "for n, filename in tqdm(enumerate(img_list, start=0), total=len(img_list)):\n",
    "    \n",
    "    # Open image from file\n",
    "    rgb_img = Image.open(os.path.join(RGB_PATH, filename))\n",
    "    \n",
    "    # Normalize RGB image in an 600x800x3 numpy array\n",
    "    rgb_array = np.array(rgb_img, dtype=np.float32) / 255.0\n",
    "    \n",
    "    # Apply mask\n",
    "    rgb_array = rgb_array * rgb_mask\n",
    "    \n",
    "    # Resize\n",
    "    rgb_array = resize(rgb_array, (IMG_WIDTH, IMG_HEIGHT), mode='reflect', anti_aliasing=True)\n",
    "    \n",
    "    # Save to dictionary\n",
    "    rgb_imgs[filename] = rgb_array\n",
    "    \n",
    "print(\"Processing IR images...\")\n",
    "\n",
    "for n, filename in tqdm(enumerate(img_list, start=0), total=len(img_list)):\n",
    "    \n",
    "    # Open image from file\n",
    "    ir_img = Image.open(os.path.join(IR_PATH, filename))\n",
    "    \n",
    "    # Normalize IR image in an 600x800 numpy array\n",
    "    ir_array = np.array(ir_img, dtype=np.float32) / 255.0\n",
    "    \n",
    "    # Apply mask\n",
    "    ir_array = ir_array * ir_mask\n",
    "    \n",
    "    # Resize\n",
    "    ir_array = resize(ir_array, (IMG_WIDTH, IMG_HEIGHT), mode='reflect', anti_aliasing=True)\n",
    "    \n",
    "    # Save to dictionary\n",
    "    ir_imgs[filename] = ir_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd29d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = rgb_imgs[filename]\n",
    "plt.imshow(img)\n",
    "\n",
    "print(np.min(img))\n",
    "print(np.max(img))\n",
    "print(np.mean(img))\n",
    "print(np.std(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804a7d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "LOAD/DECODE ANNOTATION FILES\n",
    "'''\n",
    "annotations = {}\n",
    "\n",
    "print(\"Loading annotation files...\")\n",
    "\n",
    "for n, filename in tqdm(enumerate(img_list, start=0), total=len(img_list)):\n",
    "\n",
    "    img = Image.open(os.path.join(ANNOTATIONS_PATH, filename)).resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "    encoded = np.array(img)\n",
    "\n",
    "    label = np.bitwise_or(np.bitwise_or(\n",
    "        encoded[:, :, 0].astype(np.uint32),\n",
    "        encoded[:, :, 1].astype(np.uint32) << 8),\n",
    "        encoded[:, :, 2].astype(np.uint32) << 16)\n",
    "\n",
    "    annotations[filename] = label\n",
    "\n",
    "'''\n",
    "ONE-HOT ENCODE\n",
    "'''\n",
    "annotations_onehot = {}\n",
    "class_freq = {i: 0 for i in range(num_classes)}\n",
    "\n",
    "print(\"One-hot encoding annotation files...\")\n",
    "\n",
    "for n, filename in tqdm(enumerate(img_list, start=0), total=len(img_list)):\n",
    "\n",
    "    onehot_annotation = np.zeros((IMG_HEIGHT, IMG_WIDTH, num_classes), dtype=np.uint8)\n",
    "    \n",
    "    for c in range(num_classes):\n",
    "        mask = (annotations[filename] == c)\n",
    "        onehot_annotation[..., c] = mask\n",
    "        class_freq[c] += np.sum(mask)\n",
    "    \n",
    "    annotations_onehot[filename] = onehot_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8510c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CLASS FREQUENCY PRE-AUGMENTATION\n",
    "'''\n",
    "annotation_imgs = np.array(list(annotations_onehot.values()))\n",
    "pre_aug_freq = calculate_class_frequency_set(annotation_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18625b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "FIND CANDIDATE IMAGES TO AUGMENT\n",
    "'''\n",
    "imgs_to_augment = []\n",
    "\n",
    "for key in annotations_onehot:\n",
    "    tmp, freq = find_max_class(annotations_onehot[key])\n",
    "    \n",
    "    # SOIL is dominant, so do not add to list\n",
    "    if tmp == classes.SAND:\n",
    "        imgs_to_augment.append(key)\n",
    "    elif tmp == classes.BALLAST:\n",
    "        imgs_to_augment.append(key)\n",
    "    elif tmp == classes.ROCK:\n",
    "        imgs_to_augment.append(key)\n",
    "    elif tmp == classes.BEDROCK:\n",
    "        imgs_to_augment.append(key)\n",
    "    elif tmp == classes.ROCKY_TERRAIN:\n",
    "        imgs_to_augment.append(key)\n",
    "\n",
    "# There should be 103 candidate images\n",
    "if(len(imgs_to_augment) == 103):\n",
    "    print(\"OK\")\n",
    "else:\n",
    "    print(\"Something went wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54379332",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "GENERATE AUGMENTED IMAGES\n",
    "'''\n",
    "for img in imgs_to_augment:\n",
    "    \n",
    "    # Create augmented RGB images\n",
    "    rgb_tmp = augment_image(img, rgb_imgs[img])\n",
    "    rgb_imgs.update(rgb_tmp)\n",
    "    \n",
    "    # Create augmented IR images\n",
    "    ir_tmp = augment_image(img, ir_imgs[img])\n",
    "    ir_imgs.update(ir_tmp)\n",
    "    \n",
    "    # Create augmented annotation images\n",
    "    ann_tmp = augment_image(img, annotations_onehot[img])\n",
    "    annotations_onehot.update(ann_tmp)\n",
    "    \n",
    "if(len(rgb_imgs) == 989 and len(ir_imgs) == 989 and len(annotations_onehot) == 989):\n",
    "    print(\"OK\")\n",
    "else:\n",
    "    print(\"Something went wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b625c371",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = rgb_imgs[img_list[-1]]\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe5ec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CLASS FREQUENCY POST-AUGMENTATION\n",
    "'''\n",
    "annotation_imgs = np.array(list(annotations_onehot.values()))\n",
    "post_aug_freq = calculate_class_frequency_set(annotation_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888b7ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "GENERATE NEW IMAGE LIST\n",
    "'''\n",
    "aug_img_list = list(annotations_onehot.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead527b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "FILTER EXPERIMENT 1 DATA\n",
    "'''\n",
    "exp1_pattern = r'^\\d{2}__2017-11-17-16(4[0-9]|[4-5]\\d)[0-9]{2}-0000(?:_(?:rot90|rot180|rot270|flipH|flipV))?.png$'\n",
    "exp1_img_list = [file for file in aug_img_list if re.match(exp1_pattern, file)]\n",
    "\n",
    "if(len(exp1_img_list) == 112):\n",
    "    print(\"OK\")\n",
    "else:\n",
    "    print(\"Something went wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97ab5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "SPLIT DATA\n",
    "'''\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    exp1_img_list, \n",
    "    exp1_img_list, \n",
    "    test_size=0.50, \n",
    "    train_size=0.50, \n",
    "    random_state=42, \n",
    "    shuffle=True)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, \n",
    "    y_temp, \n",
    "    test_size=0.50, \n",
    "    train_size=0.50, \n",
    "    random_state=42, \n",
    "    shuffle=False)\n",
    "\n",
    "print(\"Populating experiment 1 training data sets...\")\n",
    "exp1_rgb_X_train, exp1_ir_X_train, exp1_y_train = populate_data_sets(\n",
    "    X_train, y_train, rgb_imgs, ir_imgs, annotations_onehot)\n",
    "\n",
    "print(\"Populating experiment 1 validation data sets...\")  \n",
    "exp1_rgb_X_val, exp1_ir_X_val, exp1_y_val = populate_data_sets(\n",
    "    X_val, y_val, rgb_imgs, ir_imgs, annotations_onehot)\n",
    "\n",
    "print(\"Populating experiment 1 test data sets...\")  \n",
    "exp1_rgb_X_test, exp1_ir_X_test, exp1_y_test = populate_data_sets(\n",
    "    X_test, y_test, rgb_imgs, ir_imgs, annotations_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf7457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_train = calculate_class_frequency_set(exp1_y_train)\n",
    "print(\"\")\n",
    "\n",
    "cf_test = calculate_class_frequency_set(exp1_y_test)\n",
    "print(\"\")\n",
    "\n",
    "cf_val = calculate_class_frequency_set(exp1_y_val)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7867cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = exp1_rgb_X_train[0]\n",
    "plt.imshow(img)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584aca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP1_DIR = '/tf/Notebooks/Iwashita/Data/Preprocessed_wAugmentation/Experiment1'\n",
    "\n",
    "'''\n",
    "SAVE TRAINING DATA\n",
    "'''\n",
    "save(EXP1_DIR + '/Train/exp1_rgb_X_train.npy', exp1_rgb_X_train)\n",
    "save(EXP1_DIR + '/Train/exp1_ir_X_train.npy', exp1_ir_X_train)\n",
    "save(EXP1_DIR + '/Train/exp1_y_train.npy', exp1_y_train)\n",
    "\n",
    "'''\n",
    "SAVE VALIDATION DATA\n",
    "'''\n",
    "save(EXP1_DIR + '/Validate/exp1_rgb_X_val.npy', exp1_rgb_X_val)\n",
    "save(EXP1_DIR + '/Validate/exp1_ir_X_val.npy', exp1_ir_X_val)\n",
    "save(EXP1_DIR + '/Validate/exp1_y_val.npy', exp1_y_val)\n",
    "\n",
    "'''\n",
    "SAVE TEST DATA\n",
    "'''\n",
    "save(EXP1_DIR + '/Test/exp1_rgb_X_test.npy', exp1_rgb_X_test)\n",
    "save(EXP1_DIR + '/Test/exp1_ir_X_test.npy', exp1_ir_X_test)\n",
    "save(EXP1_DIR + '/Test/exp1_y_test.npy', exp1_y_test)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beb92bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "FILTER EXPERIMENT 2 DATA\n",
    "'''\n",
    "exp2_img_list = aug_img_list\n",
    "\n",
    "if(len(exp2_img_list) == 989):\n",
    "    print(\"OK\")\n",
    "else:\n",
    "    print(\"Something went wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbaa78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "SPLIT DATA\n",
    "'''\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    exp2_img_list, \n",
    "    exp2_img_list, \n",
    "    test_size=0.50, \n",
    "    train_size=0.50, \n",
    "    random_state=42, \n",
    "    shuffle=True)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, \n",
    "    y_temp, \n",
    "    test_size=0.50, \n",
    "    train_size=0.50, \n",
    "    random_state=42, \n",
    "    shuffle=False)\n",
    "\n",
    "print(\"Populating experiment 2 training data sets...\")\n",
    "exp2_rgb_X_train, exp2_ir_X_train, exp2_y_train = populate_data_sets(\n",
    "    X_train, y_train, rgb_imgs, ir_imgs, annotations_onehot)\n",
    "\n",
    "print(\"Populating experiment 2 validation data sets...\")  \n",
    "exp2_rgb_X_val, exp2_ir_X_val, exp2_y_val = populate_data_sets(\n",
    "    X_val, y_val, rgb_imgs, ir_imgs, annotations_onehot)\n",
    "\n",
    "print(\"Populating experiment 2 test data sets...\")  \n",
    "exp2_rgb_X_test, exp2_ir_X_test, exp2_y_test = populate_data_sets(\n",
    "    X_test, y_test, rgb_imgs, ir_imgs, annotations_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8127ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_train = calculate_class_frequency_set(exp2_y_train)\n",
    "print(\"\")\n",
    "\n",
    "cf_test = calculate_class_frequency_set(exp2_y_test)\n",
    "print(\"\")\n",
    "\n",
    "cf_val = calculate_class_frequency_set(exp2_y_val)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70042a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP2_DIR = '/tf/Notebooks/Iwashita/Data/Preprocessed_wAugmentation/Experiment2'\n",
    "\n",
    "'''\n",
    "SAVE TRAINING DATA\n",
    "'''\n",
    "save(EXP2_DIR + '/Train/exp2_rgb_X_train.npy', exp2_rgb_X_train)\n",
    "save(EXP2_DIR + '/Train/exp2_ir_X_train.npy', exp2_ir_X_train)\n",
    "save(EXP2_DIR + '/Train/exp2_y_train.npy', exp2_y_train)\n",
    "\n",
    "'''\n",
    "SAVE VALIDATION DATA\n",
    "'''\n",
    "save(EXP2_DIR + '/Validate/exp2_rgb_X_val.npy', exp2_rgb_X_val)\n",
    "save(EXP2_DIR + '/Validate/exp2_ir_X_val.npy', exp2_ir_X_val)\n",
    "save(EXP2_DIR + '/Validate/exp2_y_val.npy', exp2_y_val)\n",
    "\n",
    "'''\n",
    "SAVE TEST DATA\n",
    "'''\n",
    "save(EXP2_DIR + '/Test/exp2_rgb_X_test.npy', exp2_rgb_X_test)\n",
    "save(EXP2_DIR + '/Test/exp2_ir_X_test.npy', exp2_ir_X_test)\n",
    "save(EXP2_DIR + '/Test/exp2_y_test.npy', exp2_y_test)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9598523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "FILTER EXPERIMENT 3 DATA\n",
    "'''\n",
    "exp3_pattern = r'^\\d{2}__2017-11-17-(?:14(?:1[0-9]|[2-9][0-9])|15\\d{2}|16(?:[0-4][0-9]|5[0-9]))[0-5][0-9]-0000(?:_(?:rot90|rot180|rot270|flipH|flipV))?.png$' \n",
    "exp3_img_list = [file for file in aug_img_list if re.match(exp3_pattern, file)]\n",
    "\n",
    "exp3_test_a_pattern = r'^\\d{2}__2017-11-17-(?:1(?:[0]\\d{2}|1(?:[0-9][0-9]|2(?:[0-9][0-9]|3[0-5][0-9]))))[0-5][0-9]-0000(?:_(?:rot90|rot180|rot270|flipH|flipV))?.png$' \n",
    "exp3_test_a_list = [file for file in aug_img_list if re.match(exp3_test_a_pattern, file)]\n",
    "\n",
    "exp3_test_b_pattern = r'^\\d{2}__2017-11-17-(?:1(?:[4-6]\\d{2}|7(?:[0-2][0-9]|3[0-9])))[0-5][0-9]-0000(?:_(?:rot90|rot180|rot270|flipH|flipV))?.png$' \n",
    "exp3_test_b_list = [file for file in aug_img_list if re.match(exp3_test_b_pattern, file)]\n",
    "\n",
    "if(len(exp3_img_list) == 431 and len(exp3_test_a_list) == 338 and len(exp3_test_b_list) == 431):\n",
    "    print(\"OK\")\n",
    "else:\n",
    "    print(\"Something went wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54241b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "SPLIT DATA\n",
    "'''\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    exp3_img_list, \n",
    "    exp3_img_list, \n",
    "    test_size=0.70, \n",
    "    train_size=0.30, \n",
    "    random_state=42, \n",
    "    shuffle=True)\n",
    "\n",
    "print(\"Populating experiment 3 training data sets...\")\n",
    "exp3_rgb_X_train, exp3_ir_X_train, exp3_y_train = populate_data_sets(X_train, y_train, rgb_imgs, ir_imgs, annotations_onehot)\n",
    "\n",
    "print(\"Populating experiment 3 validation data sets...\")  \n",
    "exp3_rgb_X_val, exp3_ir_X_val, exp3_y_val = populate_data_sets(X_val, y_val, rgb_imgs, ir_imgs, annotations_onehot)\n",
    "\n",
    "print(\"Populating experiment 3 test data sets...\")  \n",
    "exp3_rgb_X_test_a, exp3_ir_X_test_a, exp3_y_test_a = populate_data_sets(exp3_test_a_list, exp3_test_a_list, rgb_imgs, ir_imgs, annotations_onehot)\n",
    "exp3_rgb_X_test_b, exp3_ir_X_test_b, exp3_y_test_b = populate_data_sets(exp3_test_b_list, exp3_test_b_list, rgb_imgs, ir_imgs, annotations_onehot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92213dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_train = calculate_class_frequency_set(exp3_y_train)\n",
    "print(\"\")\n",
    "\n",
    "cf_test = calculate_class_frequency_set(exp3_y_test_a)\n",
    "print(\"\")\n",
    "\n",
    "cf_test = calculate_class_frequency_set(exp3_y_test_b)\n",
    "print(\"\")\n",
    "\n",
    "cf_val = calculate_class_frequency_set(exp3_y_val)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806f805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP3_DIR = '/tf/Notebooks/Iwashita/Data/Preprocessed_wAugmentation/Experiment3'\n",
    "\n",
    "'''\n",
    "SAVE TRAINING DATA\n",
    "'''\n",
    "save(EXP3_DIR + '/Train/exp3_rgb_X_train.npy', exp3_rgb_X_train)\n",
    "save(EXP3_DIR + '/Train/exp3_ir_X_train.npy', exp3_ir_X_train)\n",
    "save(EXP3_DIR + '/Train/exp3_y_train.npy', exp3_y_train)\n",
    "\n",
    "'''\n",
    "SAVE VALIDATION DATA\n",
    "'''\n",
    "save(EXP3_DIR + '/Validate/exp3_rgb_X_val.npy', exp3_rgb_X_val)\n",
    "save(EXP3_DIR + '/Validate/exp3_ir_X_val.npy', exp3_ir_X_val)\n",
    "save(EXP3_DIR + '/Validate/exp3_y_val.npy', exp3_y_val)\n",
    "\n",
    "'''\n",
    "SAVE TEST DATA\n",
    "'''\n",
    "save(EXP3_DIR + '/Test/exp3_rgb_X_test_a.npy', exp3_rgb_X_test_a)\n",
    "save(EXP3_DIR + '/Test/exp3_ir_X_test_a.npy', exp3_ir_X_test_a)\n",
    "save(EXP3_DIR + '/Test/exp3_y_test_a.npy', exp3_y_test_a)\n",
    "\n",
    "save(EXP3_DIR + '/Test/exp3_rgb_X_test_b.npy', exp3_rgb_X_test_b)\n",
    "save(EXP3_DIR + '/Test/exp3_ir_X_test_b.npy', exp3_ir_X_test_b)\n",
    "save(EXP3_DIR + '/Test/exp3_y_test_b.npy', exp3_y_test_b)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d65ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
